{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125b257b-dd5a-49e3-a2d0-6e3206451ed0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T15:53:38.119834Z",
     "iopub.status.busy": "2024-11-14T15:53:38.119707Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/pring/fine-tune\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/pring/fine-tune/server/Async-Python-Server/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: unsuccessful initial attempt using frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda/envs/pytorch\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch-cuda=11.8\n",
      "    - pytorch==2.1.1\n",
      "    - torchaudio==2.1.1\n",
      "    - torchvision==0.16.1\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    brotli-python-1.0.9        |  py311h6a678d5_8         358 KB\n",
      "    ca-certificates-2024.9.24  |       h06a4308_0         130 KB\n",
      "    certifi-2024.8.30          |  py311h06a4308_0         163 KB\n",
      "    charset-normalizer-3.3.2   |     pyhd3eb1b0_0          44 KB\n",
      "    ffmpeg-4.3                 |       hf484d3e_0         9.9 MB  pytorch\n",
      "    gnutls-3.6.15              |       he1e5248_0         1.0 MB\n",
      "    idna-3.7                   |  py311h06a4308_0         133 KB\n",
      "    jpeg-9e                    |       h5eee18b_3         262 KB\n",
      "    lame-3.100                 |       h7b6447c_0         323 KB\n",
      "    libiconv-1.16              |       h5eee18b_3         759 KB\n",
      "    libidn2-2.3.4              |       h5eee18b_0         146 KB\n",
      "    libjpeg-turbo-2.0.0        |       h9bf148f_0         950 KB  pytorch\n",
      "    libtasn1-4.19.0            |       h5eee18b_0          63 KB\n",
      "    libunistring-0.9.10        |       h27cfd23_0         536 KB\n",
      "    libwebp-base-1.3.2         |       h5eee18b_1         425 KB\n",
      "    lz4-c-1.9.4                |       h6a678d5_1         156 KB\n",
      "    mkl_fft-1.3.11             |  py311h5eee18b_0         207 KB\n",
      "    mkl_random-1.2.8           |  py311ha02d727_0         328 KB\n",
      "    nettle-3.7.3               |       hbbd107a_1         809 KB\n",
      "    numpy-2.1.3                |  py311h08b1b3b_0          11 KB\n",
      "    numpy-base-2.1.3           |  py311hf175353_0         9.1 MB\n",
      "    openh264-2.1.1             |       h4ff587b_0         711 KB\n",
      "    openjpeg-2.5.2             |       he7f1fd0_0         371 KB\n",
      "    openssl-3.0.15             |       h5eee18b_0         5.2 MB\n",
      "    pillow-11.0.0              |  py311hfdbf927_0         971 KB\n",
      "    pytorch-2.1.1              |py3.11_cuda11.8_cudnn8.7.0_0        1.46 GB  pytorch\n",
      "    pytorch-cuda-11.8          |       h7e8668a_6           7 KB  pytorch\n",
      "    requests-2.32.3            |  py311h06a4308_1         126 KB\n",
      "    torchaudio-2.1.1           |      py311_cu118         6.2 MB  pytorch\n",
      "    torchvision-0.16.1         |      py311_cu118         8.3 MB  pytorch\n",
      "    urllib3-2.2.3              |  py311h06a4308_0         231 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        1.51 GB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  brotli-python      pkgs/main/linux-64::brotli-python-1.0.9-py311h6a678d5_8 \n",
      "  certifi            pkgs/main/linux-64::certifi-2024.8.30-py311h06a4308_0 \n",
      "  charset-normalizer pkgs/main/noarch::charset-normalizer-3.3.2-pyhd3eb1b0_0 \n",
      "  ffmpeg             pytorch/linux-64::ffmpeg-4.3-hf484d3e_0 \n",
      "  freetype           pkgs/main/linux-64::freetype-2.12.1-h4a9f257_0 \n",
      "  gnutls             pkgs/main/linux-64::gnutls-3.6.15-he1e5248_0 \n",
      "  idna               pkgs/main/linux-64::idna-3.7-py311h06a4308_0 \n",
      "  jpeg               pkgs/main/linux-64::jpeg-9e-h5eee18b_3 \n",
      "  lame               pkgs/main/linux-64::lame-3.100-h7b6447c_0 \n",
      "  lcms2              pkgs/main/linux-64::lcms2-2.12-h3be6417_0 \n",
      "  lerc               pkgs/main/linux-64::lerc-3.0-h295c915_0 \n",
      "  libdeflate         pkgs/main/linux-64::libdeflate-1.17-h5eee18b_1 \n",
      "  libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 \n",
      "  libidn2            pkgs/main/linux-64::libidn2-2.3.4-h5eee18b_0 \n",
      "  libjpeg-turbo      pytorch/linux-64::libjpeg-turbo-2.0.0-h9bf148f_0 \n",
      "  libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 \n",
      "  libtasn1           pkgs/main/linux-64::libtasn1-4.19.0-h5eee18b_0 \n",
      "  libtiff            pkgs/main/linux-64::libtiff-4.5.1-h6a678d5_0 \n",
      "  libunistring       pkgs/main/linux-64::libunistring-0.9.10-h27cfd23_0 \n",
      "  libwebp-base       pkgs/main/linux-64::libwebp-base-1.3.2-h5eee18b_1 \n",
      "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.4-h6a678d5_1 \n",
      "  mkl-service        pkgs/main/linux-64::mkl-service-2.4.0-py311h5eee18b_1 \n",
      "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.3.11-py311h5eee18b_0 \n",
      "  mkl_random         pkgs/main/linux-64::mkl_random-1.2.8-py311ha02d727_0 \n",
      "  nettle             pkgs/main/linux-64::nettle-3.7.3-hbbd107a_1 \n",
      "  numpy              pkgs/main/linux-64::numpy-2.1.3-py311h08b1b3b_0 \n",
      "  numpy-base         pkgs/main/linux-64::numpy-base-2.1.3-py311hf175353_0 \n",
      "  openh264           pkgs/main/linux-64::openh264-2.1.1-h4ff587b_0 \n",
      "  openjpeg           pkgs/main/linux-64::openjpeg-2.5.2-he7f1fd0_0 \n",
      "  pillow             pkgs/main/linux-64::pillow-11.0.0-py311hfdbf927_0 \n",
      "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py311h06a4308_0 \n",
      "  requests           pkgs/main/linux-64::requests-2.32.3-py311h06a4308_1 \n",
      "  torchaudio         pytorch/linux-64::torchaudio-2.1.1-py311_cu118 \n",
      "  torchvision        pytorch/linux-64::torchvision-0.16.1-py311_cu118 \n",
      "  urllib3            pkgs/main/linux-64::urllib3-2.2.3-py311h06a4308_0 \n",
      "  zstd               pkgs/main/linux-64::zstd-1.5.5-hc292b87_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                     2023.08.22-h06a4308_0 --> 2024.9.24-h06a4308_0 \n",
      "  openssl                                 3.0.11-h7f8727e_2 --> 3.0.15-h5eee18b_0 \n",
      "  pytorch                2.1.0-py3.11_cuda11.8_cudnn8.7.0_0 --> 2.1.1-py3.11_cuda11.8_cudnn8.7.0_0 \n",
      "  pytorch-cuda                              11.8-h7e8668a_5 --> 11.8-h7e8668a_6 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "torchaudio-2.1.1     | 6.2 MB    |                                       |   0% \n",
      "brotli-python-1.0.9  | 358 KB    |                                       |   0% \u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "libwebp-base-1.3.2   | 425 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "charset-normalizer-3 | 44 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lame-3.100           | 323 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libidn2-2.3.4        | 146 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "urllib3-2.2.3        | 231 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lz4-c-1.9.4          | 156 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "numpy-2.1.3          | 11 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2024 | 130 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "torchvision-0.16.1   | 8.3 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openjpeg-2.5.2       | 371 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pillow-11.0.0        | 971 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.0.15       | 5.2 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "requests-2.32.3      | 126 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libunistring-0.9.10  | 536 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mkl_fft-1.3.11       | 207 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "idna-3.7             | 133 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-4.3           | 9.9 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libiconv-1.16        | 759 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openh264-2.1.1       | 711 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mkl_random-1.2.8     | 328 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "torchaudio-2.1.1     | 6.2 MB    |                                       |   0% [A\u001b[A\u001b[A\u001b[A\n",
      "brotli-python-1.0.9  | 358 KB    | #6                                    |   4% \u001b[A\n",
      "\n",
      "\n",
      "libwebp-base-1.3.2   | 425 KB    | #3                                    |   4% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "charset-normalizer-3 | 44 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "charset-normalizer-3 | 44 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lame-3.100           | 323 KB    | #8                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "brotli-python-1.0.9  | 358 KB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "urllib3-2.2.3        | 231 KB    | ##5                                   |   7% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "libwebp-base-1.3.2   | 425 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lz4-c-1.9.4          | 156 KB    | ###8                                  |  10% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "torchaudio-2.1.1     | 6.2 MB    | ################6                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lame-3.100           | 323 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "numpy-2.1.3          | 11 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libidn2-2.3.4        | 146 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lz4-c-1.9.4          | 156 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2024 | 130 KB    | ####5                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "numpy-2.1.3          | 11 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2024 | 130 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "urllib3-2.2.3        | 231 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "urllib3-2.2.3        | 231 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openjpeg-2.5.2       | 371 KB    | #5                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pillow-11.0.0        | 971 KB    | 6                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openjpeg-2.5.2       | 371 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | 1                                     |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "requests-2.32.3      | 126 KB    | ####6                                 |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libunistring-0.9.10  | 536 KB    | #1                                    |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mkl_fft-1.3.11       | 207 KB    | ##8                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "requests-2.32.3      | 126 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.0.15       | 5.2 MB    | 1                                     |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | 2                                     |   1% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "idna-3.7             | 133 KB    | ####4                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libunistring-0.9.10  | 536 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libiconv-1.16        | 759 KB    | 7                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.0.15       | 5.2 MB    | ################3                     |  44% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | 3                                     |   1% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mkl_fft-1.3.11       | 207 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mkl_fft-1.3.11       | 207 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-4.3           | 9.9 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "torchvision-0.16.1   | 8.3 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pillow-11.0.0        | 971 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pillow-11.0.0        | 971 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openh264-2.1.1       | 711 KB    | 8                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "idna-3.7             | 133 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "idna-3.7             | 133 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | 4                                     |   1% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-4.3           | 9.9 MB    | #####1                                |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openh264-2.1.1       | 711 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libiconv-1.16        | 759 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libiconv-1.16        | 759 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mkl_random-1.2.8     | 328 KB    | #8                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "torchvision-0.16.1   | 8.3 MB    | #####6                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | 5                                     |   1% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mkl_random-1.2.8     | 328 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-4.3           | 9.9 MB    | ###############1                      |  41% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "torchvision-0.16.1   | 8.3 MB    | ##########6                           |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | 6                                     |   2% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-4.3           | 9.9 MB    | ########################7             |  67% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.0.15       | 5.2 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.0.15       | 5.2 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "torchvision-0.16.1   | 8.3 MB    | ###############6                      |  42% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | 7                                     |   2% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "torchvision-0.16.1   | 8.3 MB    | #######################3              |  63% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-4.3           | 9.9 MB    | ##################################1   |  92% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "torchvision-0.16.1   | 8.3 MB    | ####################################4 |  99% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | 8                                     |   2% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | 9                                     |   3% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #                                     |   3% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #2                                    |   3% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #3                                    |   4% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #5                                    |   4% \u001b[A\u001b[A\n",
      "\n",
      "torchaudio-2.1.1     | 6.2 MB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #8                                    |   5% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #9                                    |   5% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##1                                   |   6% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##3                                   |   6% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##4                                   |   7% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##7                                   |   7% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##9                                   |   8% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###1                                  |   9% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-4.3           | 9.9 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###3                                  |   9% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "torchvision-0.16.1   | 8.3 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###4                                  |   9% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###6                                  |  10% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###7                                  |  10% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###9                                  |  11% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####1                                 |  11% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####2                                 |  12% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####4                                 |  12% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####5                                 |  12% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####6                                 |  13% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####8                                 |  13% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #####                                 |  14% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #####1                                |  14% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #####3                                |  14% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #####5                                |  15% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #####7                                |  15% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #####9                                |  16% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ######1                               |  17% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ######3                               |  17% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ######6                               |  18% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ######8                               |  19% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #######                               |  19% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #######2                              |  20% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #######4                              |  20% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #######6                              |  21% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #######7                              |  21% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #######9                              |  21% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ########                              |  22% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ########1                             |  22% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ########2                             |  22% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ########3                             |  23% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ########4                             |  23% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ########5                             |  23% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ########6                             |  23% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ########7                             |  24% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ########9                             |  24% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #########                             |  24% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #########1                            |  25% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #########2                            |  25% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #########4                            |  25% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #########5                            |  26% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #########6                            |  26% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #########8                            |  26% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #########9                            |  27% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##########1                           |  27% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##########3                           |  28% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##########5                           |  29% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##########8                           |  29% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###########1                          |  30% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###########3                          |  31% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###########6                          |  31% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###########8                          |  32% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ############1                         |  33% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ############3                         |  33% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ############5                         |  34% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ############7                         |  34% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ############8                         |  35% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #############                         |  35% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #############1                        |  36% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #############2                        |  36% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #############4                        |  36% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #############5                        |  37% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #############6                        |  37% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #############8                        |  37% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #############9                        |  38% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##############                        |  38% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##############2                       |  38% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##############3                       |  39% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##############4                       |  39% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##############4                       |  39% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##############5                       |  39% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##############6                       |  40% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##############8                       |  40% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##############8                       |  40% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##############9                       |  41% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###############1                      |  41% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###############2                      |  41% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###############3                      |  42% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###############5                      |  42% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###############6                      |  42% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###############7                      |  43% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ################                      |  43% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ################3                     |  44% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ################5                     |  45% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ################7                     |  45% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ################9                     |  46% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #################1                    |  46% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #################2                    |  47% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #################3                    |  47% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #################4                    |  47% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #################6                    |  48% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #################8                    |  48% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #################9                    |  48% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##################                    |  49% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##################2                   |  49% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##################3                   |  50% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##################4                   |  50% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##################5                   |  50% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##################6                   |  50% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##################7                   |  51% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##################8                   |  51% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##################9                   |  51% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###################1                  |  52% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###################2                  |  52% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###################3                  |  52% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###################4                  |  53% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###################5                  |  53% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###################7                  |  53% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###################8                  |  54% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###################9                  |  54% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###################9                  |  54% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####################1                 |  54% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####################1                 |  55% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####################3                 |  55% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####################5                 |  56% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####################7                 |  56% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####################8                 |  56% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####################9                 |  57% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #####################                 |  57% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #####################1                |  57% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #####################2                |  57% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #####################2                |  58% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #####################3                |  58% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #####################4                |  58% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #####################4                |  58% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #####################6                |  58% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #####################7                |  59% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #####################8                |  59% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #####################9                |  59% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ######################                |  60% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ######################1               |  60% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ######################2               |  60% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ######################3               |  60% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ######################4               |  61% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ######################5               |  61% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ######################6               |  61% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ######################7               |  62% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ######################8               |  62% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #######################               |  62% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #######################1              |  63% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #######################3              |  63% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #######################5              |  64% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #######################6              |  64% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #######################7              |  64% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #######################9              |  65% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ########################              |  65% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ########################2             |  65% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ########################3             |  66% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ########################4             |  66% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ########################6             |  66% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ########################7             |  67% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ########################9             |  67% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #########################             |  68% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #########################2            |  68% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #########################3            |  68% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #########################4            |  69% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #########################7            |  70% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##########################            |  70% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##########################2           |  71% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##########################3           |  71% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##########################5           |  72% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##########################6           |  72% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##########################7           |  72% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##########################8           |  73% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##########################9           |  73% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###########################           |  73% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###########################3          |  74% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###########################5          |  74% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###########################6          |  75% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###########################8          |  75% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###########################9          |  76% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ############################          |  76% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ############################2         |  76% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ############################3         |  77% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ############################4         |  77% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ############################6         |  77% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ############################8         |  78% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ############################9         |  78% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #############################         |  78% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #############################1        |  79% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #############################3        |  79% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #############################4        |  80% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #############################6        |  80% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #############################7        |  81% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #############################9        |  81% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##############################1       |  81% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##############################2       |  82% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##############################3       |  82% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##############################5       |  82% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##############################6       |  83% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##############################7       |  83% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##############################8       |  83% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###############################       |  84% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###############################1      |  84% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###############################2      |  84% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###############################3      |  85% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###############################5      |  85% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###############################7      |  86% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###############################9      |  86% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ################################      |  87% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ################################2     |  87% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ################################3     |  88% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ################################5     |  88% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ################################6     |  88% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ################################7     |  89% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ################################8     |  89% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #################################     |  89% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #################################2    |  90% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #################################3    |  90% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #################################5    |  91% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #################################7    |  91% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | #################################8    |  91% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##################################    |  92% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##################################1   |  92% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##################################3   |  93% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##################################4   |  93% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##################################6   |  94% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##################################7   |  94% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##################################9   |  94% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###################################   |  95% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###################################2  |  95% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###################################3  |  95% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###################################4  |  96% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###################################6  |  96% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###################################7  |  97% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###################################8  |  97% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ###################################9  |  97% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####################################1 |  98% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####################################2 |  98% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####################################3 |  98% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####################################4 |  99% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####################################6 |  99% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####################################7 |  99% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####################################8 | 100% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ####################################9 | 100% \u001b[A\u001b[A\n",
      "\n",
      "pytorch-2.1.1        | 1.46 GB   | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "/workspace/pring/fine-tune\n",
      "/workspace/pring/fine-tune/server/Async-Python-Server\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda/envs/pytorch\n",
      "\n",
      "  added / updated specs:\n",
      "    - sentencepiece\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    libabseil-20240116.2       | cxx17_h6a678d5_0         1.3 MB\n",
      "    libprotobuf-4.25.3         |       he621ea3_0         2.8 MB\n",
      "    libsentencepiece-0.2.0     |       h70df78d_2         930 KB\n",
      "    sentencepiece-0.2.0        |       h06a4308_2          15 KB\n",
      "    sentencepiece-python-0.2.0 |  py311h3e0de92_2         3.1 MB\n",
      "    sentencepiece-spm-0.2.0    |       h70df78d_2          83 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         8.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  libabseil          pkgs/main/linux-64::libabseil-20240116.2-cxx17_h6a678d5_0 \n",
      "  libprotobuf        pkgs/main/linux-64::libprotobuf-4.25.3-he621ea3_0 \n",
      "  libsentencepiece   pkgs/main/linux-64::libsentencepiece-0.2.0-h70df78d_2 \n",
      "  sentencepiece      pkgs/main/linux-64::sentencepiece-0.2.0-h06a4308_2 \n",
      "  sentencepiece-pyt~ pkgs/main/linux-64::sentencepiece-python-0.2.0-py311h3e0de92_2 \n",
      "  sentencepiece-spm  pkgs/main/linux-64::sentencepiece-spm-0.2.0-h70df78d_2 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "libsentencepiece-0.2 | 930 KB    |                                       |   0% \n",
      "sentencepiece-spm-0. | 83 KB     |                                       |   0% \u001b[A\n",
      "\n",
      "libabseil-20240116.2 | 1.3 MB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "sentencepiece-0.2.0  | 15 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "sentencepiece-python | 3.1 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libprotobuf-4.25.3   | 2.8 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "sentencepiece-spm-0. | 83 KB     | #######1                              |  19% \u001b[A\n",
      "\n",
      "libsentencepiece-0.2 | 930 KB    | 6                                     |   2% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "sentencepiece-python | 3.1 MB    | 1                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "sentencepiece-spm-0. | 83 KB     | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libprotobuf-4.25.3   | 2.8 MB    | 2                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libsentencepiece-0.2 | 930 KB    | ############################6         |  77% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libsentencepiece-0.2 | 930 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libprotobuf-4.25.3   | 2.8 MB    | ##############2                       |  39% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "sentencepiece-0.2.0  | 15 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "sentencepiece-0.2.0  | 15 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "sentencepiece-python | 3.1 MB    | ###################################9  |  97% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libabseil-20240116.2 | 1.3 MB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "libabseil-20240116.2 | 1.3 MB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libprotobuf-4.25.3   | 2.8 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libprotobuf-4.25.3   | 2.8 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Thu Nov 14 16:00:14 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          Off |   00000000:9B:00.0 Off |                    0 |\n",
      "| N/A   35C    P0             76W /  700W |       0MiB /  38147MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "from datasets import load_dataset\n",
      "Successfully imported datasets.\n",
      "<function load_dataset at 0x7f3cc77fae80>\n",
      "from transformers import AutoModelForCausalLM\n",
      "Successfully imported transformers.\n",
      "<class 'transformers.models.auto.modeling_auto.AutoModelForCausalLM'>\n",
      "from transformers import AutoTokenizer\n",
      "Successfully imported transformers.\n",
      "<class 'transformers.models.auto.tokenization_auto.AutoTokenizer'>\n",
      "from transformers import BitsAndBytesConfig\n",
      "Successfully imported transformers.\n",
      "<class 'transformers.utils.quantization_config.BitsAndBytesConfig'>\n",
      "from transformers import HfArgumentParser\n",
      "Successfully imported transformers.\n",
      "<class 'transformers.hf_argparser.HfArgumentParser'>\n",
      "from transformers import TrainingArguments\n",
      "Successfully imported transformers.\n",
      "<class 'transformers.training_args.TrainingArguments'>\n",
      "from transformers import pipeline\n",
      "Successfully imported transformers.\n",
      "<function pipeline at 0x7f3cbaadaf20>\n",
      "from transformers import TextStreamer\n",
      "Successfully imported transformers.\n",
      "<class 'transformers.generation.streamers.TextStreamer'>\n",
      "from transformers import TextIteratorStreamer\n",
      "Successfully imported transformers.\n",
      "<class 'transformers.generation.streamers.TextIteratorStreamer'>\n",
      "from transformers import logging\n",
      "Successfully imported transformers.\n",
      "<module 'transformers.utils.logging' from '/workspace/pring/fine-tune/server/Async-Python-Server/transformers/utils/logging.py'>\n",
      "from peft import LoraConfig\n",
      "Successfully imported peft.\n",
      "<class 'peft.tuners.lora.config.LoraConfig'>\n",
      "from peft import PeftModel\n",
      "Successfully imported peft.\n",
      "<class 'peft.peft_model.PeftModel'>\n",
      "<module 'datasets' from '/workspace/pring/fine-tune/server/Async-Python-Server/datasets/__init__.py'>\n",
      "Successfully imported datasets.\n",
      "<module 'trl' from '/workspace/pring/fine-tune/server/Async-Python-Server/trl/__init__.py'>\n",
      "Successfully imported trl.\n",
      "<module 'accelerate' from '/workspace/pring/fine-tune/server/Async-Python-Server/accelerate/__init__.py'>\n",
      "Successfully imported accelerate.\n",
      "marker\n",
      "True\n",
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n",
      "{'': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 2/2 [02:14<00:00, 67.32s/it] \n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<s>[INST]  [/INST]  I'm not sure I understand what you are saying with \"]. Could you explain?\n",
      " Begriffe und Konzepte der Informatik und der Datenverarbeitung\". This book provides an overview of the key concepts and terms used in computer science and data processing. It covers topics such as algorithms, data structures, programming languages, software engineering, and data analysis.\n",
      "\n",
      "If you are looking for a specific term or concept, please let me know and I will do my best to help you.\n",
      "\n",
      "\n",
      "Platform Node:  patrick-api-0-4 \n",
      "\n",
      "Version Info:  sys.version_info(major=3, minor=11, micro=5, releaselevel='final', serial=0) \n",
      "\n",
      "Hostname:  patrick-api-0-4 \n",
      "\n",
      "FQDN:  patrick-api-0-4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/workspace/pring/fine-tune/server/Async-Python-Server')\n",
    "os.chdir('/workspace/pring/fine-tune/');\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir('/workspace/pring/fine-tune/server/Async-Python-Server')\n",
    "\n",
    "from api.llm.metapython import *\n",
    "\n",
    "import pandas\n",
    "#!rm -rf /workspace/pring/llama-2-7b-chat-hf1*\n",
    "#!pip install -U transformers\n",
    "#!conda install --yes tokenizers\n",
    "#!pip install --upgrade pip\n",
    "#!pip install tokenizers==0.15.2\n",
    "#!git clone https://github.com/NVIDIA/apex\n",
    "#!pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation --config-settings \"--build-option=--cpp_ext\" --config-settings \"--build-option=--cuda_ext\" ./apex/\n",
    "import transformers\n",
    "#!pip install transformers==4.13.0\n",
    "!conda install --yes pytorch==2.1.1 torchvision==0.16.1 torchaudio==2.1.1 pytorch-cuda=11.8 -c pytorch -c nvidia\n",
    "#!conda install --yes transformers[deepspeed]\n",
    "\n",
    "try:\n",
    "  import torch\n",
    "except:\n",
    "  !conda install --yes accelerate peft bitsandbytes transformers trl dataset torch==2.1.1\n",
    "  !conda install --yes pytorch==2.1.1\n",
    "import torch\n",
    "if (torch.cuda.is_available() == False ):\n",
    "  !conda install --yes torch==2.1.1\n",
    "  !conda install --yes accelerate peft bitsandbytes transformers trl dataset torch==2.1.1\n",
    "  import torch\n",
    "if (torch.cuda.is_available() == False ):\n",
    "    raise Exception(\"Reinstall pytorch\")\n",
    "    \n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/workspace/pring/fine-tune/server/Async-Python-Server')\n",
    "os.chdir('/workspace/pring/fine-tune/');\n",
    "import torch\n",
    "import transformers\n",
    "print(os.getcwd())\n",
    "os.chdir('/workspace/pring/fine-tune/server/Async-Python-Server');\n",
    "print(os.getcwd())\n",
    "import pandas\n",
    "from urllib.parse import quote\n",
    "from urllib.parse import unquote\n",
    "import time\n",
    "!conda install --yes sentencepiece\n",
    "import sentencepiece\n",
    "import tensorboardX\n",
    "\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "gc.collect()\n",
    "\n",
    "magic('nvidia-smi')\n",
    "\n",
    "import sys\n",
    "fromImport(\"datasets\",[\"load_dataset\"])\n",
    "fromImport(\"transformers\",[\"AutoModelForCausalLM\", \"AutoTokenizer\",\"BitsAndBytesConfig\",\"HfArgumentParser\",\"TrainingArguments\",\"pipeline\",\"TextStreamer\",\"TextIteratorStreamer\",\"logging\"])\n",
    "fromImport(\"peft\",[\"LoraConfig\", \"PeftModel\"])\n",
    "from trl import SFTTrainer\n",
    "import time\n",
    "importLib(\"datasets\")\n",
    "importLib(\"trl\")\n",
    "importLib(\"accelerate\")\n",
    "from threading import Thread\n",
    "#from api.xpy import *\n",
    "\n",
    "#model_name = \"Weblet/llama-2-usaaef2c\"\n",
    "model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# QLoRA parameters\n",
    "################################################################################\n",
    "lora_r = 64 # LoRA attention dimension\n",
    "lora_alpha = 16 # Alpha parameter for LoRA scaling\n",
    "lora_dropout = 0.1 # Dropout probability for LoRA layers\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "use_4bit = True # Activate 4-bit precision base model loading\n",
    "bnb_4bit_compute_dtype = \"float16\" # Compute dtype for 4-bit base models\n",
    "bnb_4bit_quant_type = \"nf4\" # Quantization type (fp4 or nf4)\n",
    "use_nested_quant = False # Activate nested quantization for 4-bit base models (double quantization)\n",
    "\n",
    "################################################################################\n",
    "# TrainingArguments parameters\n",
    "################################################################################\n",
    "output_dir = \"./results\" # Output directory where the model predictions and checkpoints will be stored\n",
    "num_train_epochs = 1 # Number of training epochs\n",
    "fp16 = False # Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "bf16 = False\n",
    "per_device_train_batch_size = 1 # Batch size per GPU for training\n",
    "per_device_eval_batch_size = 1 # Batch size per GPU for evaluation\n",
    "gradient_accumulation_steps = 1 # Number of update steps to accumulate the gradients for\n",
    "gradient_checkpointing = True # Enable gradient checkpointing\n",
    "max_grad_norm = 0.3 # Maximum gradient normal (gradient clipping)\n",
    "learning_rate = 2e-4 # Initial learning rate (AdamW optimizer)\n",
    "weight_decay = 0.001 # Weight decay to apply to all layers except bias/LayerNorm weights\n",
    "optim = \"paged_adamw_32bit\" #\"adamw_apex_fused\"# Optimizer to use\n",
    "lr_scheduler_type = \"cosine\" # Learning rate schedule\n",
    "max_steps = -1 # Number of training steps (overrides num_train_epochs)\n",
    "warmup_ratio = 0.03 # Ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "group_by_length = False # Group sequences into batches with same length # Saves memory and speeds up training considerably\n",
    "save_steps = 0 # Save checkpoint every X updates steps\n",
    "logging_steps = 25 # Log every X updates steps\n",
    "\n",
    "################################################################################\n",
    "# SFT parameters\n",
    "################################################################################\n",
    "max_seq_length = 512 # Maximum sequence length to use\n",
    "packing = False # Pack multiple short examples in the same input sequence to increase efficiency\n",
    "device_map = {\"\": 0} #  Load the entire model on the GPU 0\n",
    "import gc\n",
    "gc.collect()\n",
    "gc.collect()\n",
    "\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "print(\"marker\")\n",
    "\n",
    "\n",
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "try:\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=use_4bit,\n",
    "        bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "        bnb_4bit_compute_dtype=compute_dtype,\n",
    "        bnb_4bit_use_double_quant=use_nested_quant,\n",
    "    )\n",
    "except:\n",
    "    magic('%pip install -U bitsandbytes');\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=use_4bit,\n",
    "        bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "        bnb_4bit_compute_dtype=compute_dtype,\n",
    "        bnb_4bit_use_double_quant=use_nested_quant,\n",
    "    )\n",
    "print(use_4bit)\n",
    "# Check GPU compatibility with bfloat16\n",
    "try:\n",
    "  if compute_dtype == torch.float16 and use_4bit:\n",
    "      major, _ = torch.cuda.get_device_capability()\n",
    "      if major >= 8:\n",
    "          print(\"=\" * 80)\n",
    "          print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "          print(\"=\" * 80)\n",
    "except:\n",
    "  device_map = \"cpu\"\n",
    "\n",
    "print(device_map)\n",
    "# Load base model\n",
    "try:\n",
    "  model = AutoModelForCausalLM.from_pretrained(model_name,quantization_config=bnb_config,device_map=device_map,trust_remote_code=True)\n",
    "except:\n",
    "  model = AutoModelForCausalLM.from_pretrained(model_name,device_map=device_map,trust_remote_code=True)\n",
    "model.config.use_cache = True\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\" \n",
    "\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "from api.xpy import *\n",
    "def streamWriter(str):\n",
    "    txt=''\n",
    "    transaction_id=''\n",
    "    for s in str:\n",
    "        txt+=tokenizer.decode(s)\n",
    "        if 'ESNOPSER_ID' in txt:\n",
    "            transaction_id=txt.split('ESNOPSER_ID')[1].split('<')[0].split('[')[0];\n",
    "            transaction_id\n",
    "   # print(txt)\n",
    "    stream=streamWriter.responseStream\n",
    "    if at(streamWriter.requestMap,[transaction_id]) != None:\n",
    "        stream = at(streamWriter.requestMap,[transaction_id])\n",
    "    if stream != None:\n",
    "        zwrite_response_body(streamWriter.responseStream, b(f\"{txt} \"))\n",
    "streamWriter.responseStream=None\n",
    "streamWriter.requestMap={}\n",
    "streamer.put=streamWriter\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=max_seq_length,streamer=streamer)\n",
    "\n",
    "prompt_seed = \"\"# \"\"\"You are a chatbot with the purpose of serving USAA members. Your goal is to give sound financial advice to USAA members and to direct USAA members where to find additional resources to guide them through their financial journey.\"\"\"\n",
    "\n",
    "\n",
    "def talk(prompt):\n",
    "    result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "    return result[0]['generated_text']\n",
    "async def talks(prompt,transaction_id=''):\n",
    "    return pipe(f\"<pre>{prompt_seed}</pre>{transaction_id}<s>[INST] I am curious. {prompt} [/INST]\")\n",
    "\n",
    "\n",
    "\n",
    "print(talk(prompt_seed))\n",
    "\n",
    "#os.chdir('/workspace/pring/fine-tune/server/Async-Python-Server');\n",
    "\n",
    "from http.server import ThreadingHTTPServer, BaseHTTPRequestHandler\n",
    "import http.client\n",
    "import asyncio\n",
    "import time\n",
    "from api.xpy import *\n",
    "import socket\n",
    "import platform\n",
    "from http.server import ThreadingHTTPServer, BaseHTTPRequestHandler\n",
    "import asyncio\n",
    "from api.promises import *\n",
    "from api.excepts import *\n",
    "from api.xhttp import *\n",
    "from api.zfile import *\n",
    "from api.xpy import *\n",
    "import mimetypes\n",
    "mimetypes.init()\n",
    "\n",
    "#os.chdir('/workspace/pring/fine-tune/');\n",
    "\n",
    "class handler(BaseHTTPRequestHandler):\n",
    "\n",
    "  async def do_ASYNC(request, data):\n",
    "      print(f\"Recieved {request.path}\")\n",
    "      if(request.path.startswith('/llama')):\n",
    "          transaction_id=f\"ESNOPSER_ID{time.time()}\".replace('.','');\n",
    "          streamWriter.responseStream=request\n",
    "          streamWriter.requestMap[transaction_id]=request;\n",
    "          await zsendHeaders(request,{\n",
    "              'status':200,\n",
    "              'Content-type':'text/plain',\n",
    "              'Access-Control-Allow-Origin':'*'\n",
    "          })\n",
    "          content=await talks(unquote(f\"{at(request.path.split('/llama?'),[1])}\"),transaction_id=transaction_id)\n",
    "          text=f\"[FULLTEXT]{content[0]['generated_text']}\"\n",
    "          print(f'responding{text}')\n",
    "          await zwriteResponseBody(request, b(text))\n",
    "          del streamWriter.requestMap[transaction_id]\n",
    "      else:\n",
    "          path = f\"/workspace/pring/fine-tune/server/Async-Python-Server{request.path}\".split(\"?\")[0].split(\"#\")[0];\n",
    "          contentType = mimetypes.guess_type(path,strict=False)\n",
    "          print(path,contentType[0])\n",
    "          content = await zreadFileBytes(path)\n",
    "          await zsendHeaders(request,{'status':200,'Content-type':contentType[0]})\n",
    "          await zwriteResponseBody(request, content)\n",
    "\n",
    "  def do_METHOD(request):\n",
    "    asyncio.run(request.do_ASYNC(request))\n",
    "\n",
    "  do_GET = do_METHOD\n",
    "  do_OPTIONS = do_METHOD\n",
    "  do_POST = do_METHOD\n",
    "  do_PUT = do_METHOD\n",
    "  do_PATCH = do_METHOD\n",
    "  do_HEAD = do_METHOD\n",
    "  do_DELETE = do_METHOD\n",
    "  do_CONNECT = do_METHOD\n",
    "  do_TRACE = do_METHOD\n",
    "\n",
    "println(\"\\n\\nPlatform Node: \",platform.node())\n",
    "println(\"Version Info: \",sys.version_info)\n",
    "println(\"Hostname: \",socket.gethostname())\n",
    "println(\"FQDN: \",socket.getfqdn())\n",
    "\n",
    "httpd = ThreadingHTTPServer(('', 80), handler)\n",
    "httpd.timeout = 30\n",
    "httpd.serve_forever()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
